{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a11bafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "\n",
    "from sklearn.feature_selection import *\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import *\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.model_selection import RepeatedKFold, cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from get_data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4405cc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features according having k highest-score values or statistics\n",
    "class FeaturesWithSelectKBest(TransformerMixin, BaseEstimator):\n",
    "    \n",
    "    def __init__(self, score_func=f_classif):\n",
    "        self.score_func = score_func     # the method to use (For Regression lookup scikit_learn.feature_selection)\n",
    "        return None\n",
    "    \n",
    "    def fit(self, df, y):\n",
    "        num_features = int(2*df.shape[1]/3 + 0.5)\n",
    "        self.selector = SelectKBest(self.score_func, k=num_features)\n",
    "\n",
    "         # fit transform based on score_func and number of features to select\n",
    "        self.selector = self.selector.fit(df, y)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, df, y=None):\n",
    "        # call the fit_transform method and get data using best features \n",
    "        return self.selector.transform(df) \n",
    "\n",
    "# Select features with high correlation with target and low correlation with other features\n",
    "class FeaturesWithCorrelations(TransformerMixin, BaseEstimator):\n",
    "    \n",
    "    def __init__(self, pval_X_y = 0.5, pval_X_X=0.75):\n",
    "        self.pval_X_y = pval_X_y   # cut-off value for feature-target correlation\n",
    "        self.pval_X_X = pval_X_X   # cut-off value for feature-feature correlation\n",
    "        return None\n",
    "    \n",
    "    def fit(self, df, y):\n",
    "        df2 = pd.DataFrame(df) # This ensures the column names are k=0,1,2 same as array indexing df[:, k]\n",
    "                \n",
    "        # Select feature_index that are correlated (wrt pval) with the target variable\n",
    "        self.corr_X_y = [col for col in df2.columns if np.abs(pearsonr(df2[col], y)[0]) > self.pval_X_y] \n",
    "\n",
    "        # Compute feature/feature correlation for each feature\n",
    "        corr_matrix = df2.corr().abs()\n",
    "             \n",
    "        # select feature_index with low feature/feature correlation\n",
    "        self.corr_X_X = [col for col in corr_matrix if (corr_matrix[col][0:col-1] < self.pval_X_X).all()]\n",
    "        return self\n",
    "    \n",
    "    def transform(self, df, y=None):\n",
    "        # select features with high feature-target correlation and low feature-feature-correlation\n",
    "        keep_index  = np.array(list(set(self.corr_X_y) & set(self.corr_X_X)))\n",
    "        if len(keep_index) == 0: # Either self>corr_X_y is empty or self.corr_X_X.empty\n",
    "            keep_index  = np.array(list(set(self.corr_X_y) | set(self.corr_X_X)))  # Select that which is not empty\n",
    "        return df[:, keep_index]        \n",
    "    \n",
    "    \n",
    "class RecursiveFeatureElimination(TransformerMixin, BaseEstimator):\n",
    "    \n",
    "    def __init__(self, num_features, model=LogisticRegression()):\n",
    "        self.model = model               # model to use for feature elimination\n",
    "        self.num_features = num_features # num_features to select\n",
    "        return None\n",
    "    \n",
    "    def fit(self, df, y):               \n",
    "        # fit the data and get the best features\n",
    "        rfecv = RFECV(self.model, min_features_to_select=self.num_features)\n",
    "        self.rfecv = rfecv.fit(df, y.ravel())  \n",
    "        return self\n",
    "        \n",
    "    def transform(self, df, y=None):\n",
    "        # Get the best features \n",
    "        selections = self.rfecv.get_support()\n",
    "        return df[:, selections]\n",
    "    \n",
    "    \n",
    "\n",
    "class FeaturesWithSelectFromModel(TransformerMixin, BaseEstimator):\n",
    "    \n",
    "    def __init__(self, base_model = ExtraTreesClassifier(n_estimators=50)):\n",
    "        self.base_model = base_model\n",
    "        self.selector = SelectFromModel(estimator=self.base_model)\n",
    "        return None\n",
    "        \n",
    "    def fit(self, df, y):\n",
    "        # fit transform based on score_func and number of features to select\n",
    "        self.selector = self.selector.fit(df, y) \n",
    "        return self\n",
    "    \n",
    "    def transform(self, df, y=None):    \n",
    "        # Get the best features after fit       \n",
    "        return self.selector.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fd0546b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(df, y):\n",
    "    # Make pipeline with StandardScaler for each feature_selection method\n",
    "    # The standardScaler is used in the event we have some features with high cardinality\n",
    "    selectKBest_f_classif = make_pipeline(StandardScaler(),\\\n",
    "                                           FeaturesWithSelectKBest(),\\\n",
    "                                           LogisticRegression())\n",
    "      \n",
    "    selectKBest_mutual_info_classif = make_pipeline(StandardScaler(),\\\n",
    "                                           FeaturesWithSelectKBest(score_func=mutual_info_classif),\\\n",
    "                                           LogisticRegression())\n",
    "    selectFromModel = make_pipeline(StandardScaler(),\\\n",
    "                                    FeaturesWithSelectFromModel(),\\\n",
    "                                    LogisticRegression())\n",
    "    features_with_correlations = make_pipeline(StandardScaler(),\\\n",
    "                                              FeaturesWithCorrelations(),\\\n",
    "                                              LogisticRegression())\n",
    "    recursive_feature_elimination = make_pipeline(StandardScaler(),\\\n",
    "                                              RecursiveFeatureElimination(num_features=5),\\\n",
    "                                              LogisticRegression())\n",
    "    \n",
    "    # Loop over each model and perform a cross validation test\n",
    "    models = [selectKBest_f_classif, selectKBest_mutual_info_classif,\\\n",
    "             recursive_feature_elimination, features_with_correlations,\\\n",
    "              selectFromModel]\n",
    "    score_type = 'accuracy'\n",
    "\n",
    "    CV = RepeatedKFold(n_splits=10, n_repeats=10)\n",
    "    cv_results = np.array([cross_val_score(model, df, y, cv=CV, scoring=score_type) for model in models]).T\n",
    "    cv_results = np.mean(cv_results, axis=0).reshape((1,-1))[0]\n",
    "    return cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3bbf364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Breat_cancer</th>\n",
       "      <th>Wine</th>\n",
       "      <th>Iris</th>\n",
       "      <th>Glass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f_classif</th>\n",
       "      <td>0.955797</td>\n",
       "      <td>0.966176</td>\n",
       "      <td>0.954667</td>\n",
       "      <td>0.878333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mutual_info</th>\n",
       "      <td>0.950942</td>\n",
       "      <td>0.971961</td>\n",
       "      <td>0.954000</td>\n",
       "      <td>0.900563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>selectFromModel</th>\n",
       "      <td>0.957089</td>\n",
       "      <td>0.987647</td>\n",
       "      <td>0.953333</td>\n",
       "      <td>0.895303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_correlations</th>\n",
       "      <td>0.944195</td>\n",
       "      <td>0.936144</td>\n",
       "      <td>0.958000</td>\n",
       "      <td>0.598636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RFE</th>\n",
       "      <td>0.947201</td>\n",
       "      <td>0.980850</td>\n",
       "      <td>0.953333</td>\n",
       "      <td>0.811558</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Breat_cancer      Wine      Iris     Glass\n",
       "f_classif                 0.955797  0.966176  0.954667  0.878333\n",
       "mutual_info               0.950942  0.971961  0.954000  0.900563\n",
       "selectFromModel           0.957089  0.987647  0.953333  0.895303\n",
       "feature_correlations      0.944195  0.936144  0.958000  0.598636\n",
       "RFE                       0.947201  0.980850  0.953333  0.811558"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    \n",
    "    column = ['Breat_cancer', 'Wine', 'Iris', 'Glass']\n",
    "    index = ['f_classif', 'mutual_info', 'selectFromModel','feature_correlations', 'RFE']\n",
    "\n",
    "    # Execute the experiments\n",
    "    breast_cancer_X, breast_cancer_y = breast_cancer_data()\n",
    "    breast_cancer_result = experiment(breast_cancer_X, breast_cancer_y)\n",
    "    \n",
    "    wine_data_X, wine_data_y = load_wine(return_X_y=True)\n",
    "    wine_result = experiment(wine_data_X, wine_data_y)\n",
    "    \n",
    "    iris_data_X, iris_data_y = load_iris(return_X_y=True)\n",
    "    iris_result = experiment(iris_data_X, iris_data_y)  \n",
    "    \n",
    "    glass_data_X, glass_data_y = glass_data()\n",
    "    glass_result = experiment(glass_data_X, glass_data_y)  \n",
    "    \n",
    "    all_results = np.array([breast_cancer_result, wine_result, \\\n",
    "                            iris_result, glass_result]).T\n",
    "\n",
    "    df = pd.DataFrame(all_results, index=index, columns=column)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6676208",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2625074",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3c8961",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05edf81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04648d6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },

 "nbformat": 4,
 "nbformat_minor": 5
}

